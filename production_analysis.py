#!/usr/bin/env python3
"""
Script de producci√≥n para an√°lisis completo del dataset con mREBEL
Genera estad√≠sticas detalladas para toma de decisiones sobre umbrales de confianza
"""

import os
import sys
import json
import time
from collections import defaultdict, Counter
from datetime import datetime
import pandas as pd

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src', 'extract'))

def production_analysis():
    """An√°lisis completo del dataset para producci√≥n"""
    
    print("üöÄ AN√ÅLISIS DE PRODUCCI√ìN - DATASET COMPLETO")
    print("=" * 80)
    print(f"Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    try:
        # Importar despu√©s de configurar el path
        from mrebel_wrapper import load_mrebel, run_mrebel
        
        # Cargar modelo
        print("üîÑ Cargando modelo mREBEL...")
        start_time = time.time()
        model, tokenizer = load_mrebel(
            "Babelscape/mrebel-large",
            verify_cuda=False
        )
        load_time = time.time() - start_time
        print(f"‚úÖ Modelo cargado en {load_time:.1f} segundos")
        
        # Leer dataset
        print("üìñ Cargando dataset...")
        dataset_dir = "data/interim"
        
        if not os.path.exists(dataset_dir):
            print(f"‚ùå Directorio no encontrado: {dataset_dir}")
            return
        
        # Leer archivos JSON del directorio interim
        texts = []
        text_ids = []
        json_files = [f for f in os.listdir(dataset_dir) if f.endswith('.json')][:50]  # Limitar a 50 archivos
        
        print(f"üìÅ Encontrados {len(json_files)} archivos JSON, procesando primeros 50...")
        
        for json_file in json_files:
            file_path = os.path.join(dataset_dir, json_file)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    # Extraer texto de chunks
                    if 'chunks' in data and data['chunks']:
                        # Unir todos los chunks en un solo texto
                        full_text = ' '.join(data['chunks'])
                        texts.append(full_text)
                        text_ids.append(data.get('source', json_file.replace('.json', '')))
                        
            except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:
                print(f"   ‚ö†Ô∏è  Error procesando {json_file}: {e}")
                continue
        
        if not texts:
            print("‚ùå No se pudieron cargar textos del dataset")
            return
        
        print(f"üìä Dataset cargado: {len(texts)} textos para an√°lisis")
        print(f"üìù Muestra: {texts[0][:100]}...")
        
        # === PROCESAMIENTO ===
        print("\\nüîÑ PROCESANDO TEXTOS...")
        start_processing = time.time()
        
        all_results = []
        confidence_stats = {
            'all_confidences': [],
            'by_relation_type': defaultdict(list),
            'by_text_length': defaultdict(list),
            'triplets_per_text': [],
            'failed_extractions': 0,
            'processing_times': []
        }
        
        # Procesar textos
        for i, (text_id, text) in enumerate(zip(text_ids, texts)):
            text_start = time.time()
            
            # Progreso cada 10 textos
            if i % 10 == 0:
                elapsed = time.time() - start_processing
                rate = (i + 1) / elapsed if elapsed > 0 else 0
                eta = (len(texts) - i - 1) / rate if rate > 0 else 0
                print(f"   {i+1:3d}/{len(texts)} | {rate:.1f} txt/s | ETA: {eta:.0f}s | {text[:50]}...")
            
            try:
                # Procesar texto
                results = run_mrebel(text, model, tokenizer)
                text_time = time.time() - text_start
                confidence_stats['processing_times'].append(text_time)
                
                if results:
                    # Informaci√≥n del texto
                    text_length = len(text.split())
                    confidence_stats['triplets_per_text'].append(len(results))
                    
                    # Clasificar por longitud de texto
                    if text_length < 20:
                        length_category = 'short'
                    elif text_length < 50:
                        length_category = 'medium'
                    else:
                        length_category = 'long'
                    
                    # Procesar cada triplete
                    for triplet in results:
                        conf = triplet.get('confidence', 0.5)
                        relation_type = triplet['type']
                        
                        # Almacenar resultado completo
                        result_entry = {
                            'text_id': text_id,
                            'text': text,
                            'text_length': text_length,
                            'length_category': length_category,
                            'head': triplet['head'],
                            'head_type': triplet.get('head_type', ''),
                            'relation': relation_type,
                            'tail': triplet['tail'],
                            'tail_type': triplet.get('tail_type', ''),
                            'confidence': conf,
                            'processing_time': text_time
                        }
                        all_results.append(result_entry)
                        
                        # Estad√≠sticas
                        confidence_stats['all_confidences'].append(conf)
                        confidence_stats['by_relation_type'][relation_type].append(conf)
                        confidence_stats['by_text_length'][length_category].append(conf)
                else:
                    confidence_stats['failed_extractions'] += 1
                    
            except Exception as e:
                print(f"      ‚ùå Error procesando texto {i}: {e}")
                confidence_stats['failed_extractions'] += 1
        
        processing_time = time.time() - start_processing
        print(f"\\n‚úÖ Procesamiento completado en {processing_time:.1f} segundos")
        
        # === AN√ÅLISIS ESTAD√çSTICO ===
        print("\\nüìä GENERANDO ESTAD√çSTICAS...")
        
        total_texts = len(texts)
        total_triplets = len(all_results)
        successful_texts = total_texts - confidence_stats['failed_extractions']
        
        # Estad√≠sticas b√°sicas
        basic_stats = {
            'dataset_info': {
                'total_texts': total_texts,
                'successful_extractions': successful_texts,
                'failed_extractions': confidence_stats['failed_extractions'],
                'success_rate': successful_texts / total_texts * 100,
                'total_triplets': total_triplets,
                'avg_triplets_per_text': sum(confidence_stats['triplets_per_text']) / len(confidence_stats['triplets_per_text']) if confidence_stats['triplets_per_text'] else 0,
                'avg_processing_time': sum(confidence_stats['processing_times']) / len(confidence_stats['processing_times']) if confidence_stats['processing_times'] else 0
            }
        }
        
        # Distribuci√≥n de confianza
        confidences = confidence_stats['all_confidences']
        if confidences:
            # Percentiles
            confidences_sorted = sorted(confidences)
            n = len(confidences_sorted)
            
            confidence_distribution = {
                'total_triplets': len(confidences),
                'mean': sum(confidences) / len(confidences),
                'median': confidences_sorted[n//2],
                'min': min(confidences),
                'max': max(confidences),
                'percentiles': {
                    'p10': confidences_sorted[int(n * 0.1)],
                    'p25': confidences_sorted[int(n * 0.25)],
                    'p50': confidences_sorted[int(n * 0.5)],
                    'p75': confidences_sorted[int(n * 0.75)],
                    'p90': confidences_sorted[int(n * 0.9)],
                    'p95': confidences_sorted[int(n * 0.95)],
                    'p99': confidences_sorted[int(n * 0.99)]
                }
            }
            
            # Distribuci√≥n por rangos
            ranges = {
                'excellent_099_100': sum(1 for c in confidences if c >= 0.99),
                'very_high_095_099': sum(1 for c in confidences if 0.95 <= c < 0.99),
                'high_090_095': sum(1 for c in confidences if 0.90 <= c < 0.95),
                'good_080_090': sum(1 for c in confidences if 0.80 <= c < 0.90),
                'medium_070_080': sum(1 for c in confidences if 0.70 <= c < 0.80),
                'low_050_070': sum(1 for c in confidences if 0.50 <= c < 0.70),
                'very_low_000_050': sum(1 for c in confidences if c < 0.50)
            }
            
            confidence_distribution['ranges'] = ranges
            confidence_distribution['ranges_percentages'] = {
                k: v / len(confidences) * 100 for k, v in ranges.items()
            }
        
        # An√°lisis por tipo de relaci√≥n
        relation_analysis = {}
        for relation_type, confs in confidence_stats['by_relation_type'].items():
            if len(confs) >= 2:  # Solo analizar relaciones con al menos 2 casos
                relation_analysis[relation_type] = {
                    'count': len(confs),
                    'mean_confidence': sum(confs) / len(confs),
                    'min_confidence': min(confs),
                    'max_confidence': max(confs),
                    'high_confidence_count': sum(1 for c in confs if c >= 0.9),
                    'high_confidence_percentage': sum(1 for c in confs if c >= 0.9) / len(confs) * 100
                }
        
        # Top relaciones por frecuencia y confianza
        top_relations_by_frequency = sorted(
            relation_analysis.items(), 
            key=lambda x: x[1]['count'], 
            reverse=True
        )[:10]
        
        top_relations_by_confidence = sorted(
            relation_analysis.items(), 
            key=lambda x: x[1]['mean_confidence'], 
            reverse=True
        )[:10]
        
        # === GUARDAR RESULTADOS ===
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = f"analysis_results_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)
        
        # Guardar datos completos
        results_file = os.path.join(output_dir, "complete_results.jsonl")
        with open(results_file, 'w', encoding='utf-8') as f:
            for result in all_results:
                f.write(json.dumps(result, ensure_ascii=False) + '\\n')
        
        # Guardar estad√≠sticas
        stats_file = os.path.join(output_dir, "statistics.json")
        full_stats = {
            'basic_stats': basic_stats,
            'confidence_distribution': confidence_distribution,
            'relation_analysis': relation_analysis,
            'top_relations_by_frequency': top_relations_by_frequency,
            'top_relations_by_confidence': top_relations_by_confidence,
            'processing_info': {
                'total_processing_time': processing_time,
                'texts_per_second': len(texts) / processing_time,
                'triplets_per_second': total_triplets / processing_time,
                'timestamp': timestamp
            }
        }
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(full_stats, f, indent=2, ensure_ascii=False)
        
        # === GENERAR REPORTE VISUAL ===
        print("\\nüìà REPORTE DE AN√ÅLISIS")
        print("=" * 80)
        
        print(f"üìä INFORMACI√ìN B√ÅSICA:")
        print(f"   ‚Ä¢ Textos procesados: {total_texts}")
        print(f"   ‚Ä¢ Extracciones exitosas: {successful_texts} ({successful_texts/total_texts*100:.1f}%)")
        print(f"   ‚Ä¢ Total tripletes: {total_triplets}")
        print(f"   ‚Ä¢ Promedio tripletes/texto: {basic_stats['dataset_info']['avg_triplets_per_text']:.1f}")
        print(f"   ‚Ä¢ Tiempo promedio/texto: {basic_stats['dataset_info']['avg_processing_time']:.2f}s")
        
        if confidences:
            print(f"\\nüéØ DISTRIBUCI√ìN DE CONFIANZA:")
            print(f"   ‚Ä¢ Confianza promedio: {confidence_distribution['mean']:.3f}")
            print(f"   ‚Ä¢ Mediana: {confidence_distribution['median']:.3f}")
            print(f"   ‚Ä¢ Rango: {confidence_distribution['min']:.3f} - {confidence_distribution['max']:.3f}")
            
            print(f"\\nüìä PERCENTILES CLAVE:")
            for p, v in confidence_distribution['percentiles'].items():
                print(f"   ‚Ä¢ {p.upper()}: {v:.3f}")
            
            print(f"\\nüé® DISTRIBUCI√ìN POR RANGOS:")
            for range_name, percentage in confidence_distribution['ranges_percentages'].items():
                count = confidence_distribution['ranges'][range_name]
                range_display = range_name.replace('_', ' ').title().replace(' ', ' ')
                print(f"   ‚Ä¢ {range_display:20}: {count:4d} ({percentage:5.1f}%)")
            
            print(f"\\nüèÜ TOP 5 RELACIONES M√ÅS FRECUENTES:")
            for i, (rel_type, stats) in enumerate(top_relations_by_frequency[:5]):
                print(f"   {i+1}. {rel_type:30} | {stats['count']:3d} casos | conf: {stats['mean_confidence']:.3f}")
            
            print(f"\\n‚≠ê TOP 5 RELACIONES M√ÅS CONFIABLES:")
            for i, (rel_type, stats) in enumerate(top_relations_by_confidence[:5]):
                print(f"   {i+1}. {rel_type:30} | {stats['count']:3d} casos | conf: {stats['mean_confidence']:.3f}")
        
        print(f"\\nüíæ RESULTADOS GUARDADOS EN: {output_dir}/")
        print(f"   ‚Ä¢ complete_results.jsonl - Todos los tripletes extra√≠dos")
        print(f"   ‚Ä¢ statistics.json - Estad√≠sticas completas")
        
        # === RECOMENDACIONES ===
        print(f"\\nüéØ RECOMENDACIONES PARA UMBRALES:")
        if confidences:
            p95 = confidence_distribution['percentiles']['p95']
            p90 = confidence_distribution['percentiles']['p90']
            p75 = confidence_distribution['percentiles']['p75']
            p50 = confidence_distribution['percentiles']['p50']
            
            print(f"   ‚Ä¢ ALTA CONFIANZA (usar directamente): ‚â• {p90:.3f} ({sum(1 for c in confidences if c >= p90)}/{len(confidences)} casos, {sum(1 for c in confidences if c >= p90)/len(confidences)*100:.1f}%)")
            print(f"   ‚Ä¢ CONFIANZA MEDIA (revisar): {p75:.3f} - {p90:.3f} ({sum(1 for c in confidences if p75 <= c < p90)}/{len(confidences)} casos)")
            print(f"   ‚Ä¢ BAJA CONFIANZA (verificar): < {p75:.3f} ({sum(1 for c in confidences if c < p75)}/{len(confidences)} casos)")
        
        print(f"\\n‚úÖ AN√ÅLISIS COMPLETADO")
        print(f"Tiempo total: {time.time() - start_time:.1f} segundos")
        print("=" * 80)
        
        # Limpiar memoria
        del model
        import torch
        torch.cuda.empty_cache()
        
    except Exception as e:
        print(f"‚ùå Error durante el an√°lisis: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    production_analysis()